{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read file and display some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of ratings 100000\n",
      "First ten rows\n",
      "   userid  itemid  rating  timestamp\n",
      "0     196     242       3  881250949\n",
      "1     186     302       3  891717742\n",
      "2      22     377       1  878887116\n",
      "3     244      51       2  880606923\n",
      "4     166     346       1  886397596\n",
      "5     298     474       4  884182806\n",
      "6     115     265       2  881171488\n",
      "7     253     465       5  891628467\n",
      "8     305     451       3  886324817\n",
      "9       6      86       3  883603013\n"
     ]
    }
   ],
   "source": [
    "names = ['userid', 'itemid', 'rating', 'timestamp']\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "\n",
    "print('Count of ratings', len(data))\n",
    "print('First ten rows')\n",
    "print(data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-based collaborativve filtering approach using Pearson correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = userids, data = whole data set\n",
    "def pearson_correlation(a, b, data):\n",
    "    # rows from data set containing given userids\n",
    "    data_a = data.loc[data['userid'] == a]\n",
    "    data_b = data.loc[data['userid'] == b]\n",
    "\n",
    "    # dicts with itemid and ratings\n",
    "    dict_a = dict(zip(data_a.itemid, data_a.rating))\n",
    "    dict_b = dict(zip(data_b.itemid, data_b.rating))\n",
    "\n",
    "    # intersections of common itemids\n",
    "    P = list(set(dict_a).intersection(set(dict_b)))\n",
    "\n",
    "    # keep only common itemids\n",
    "    dict_a = {id: dict_a[id] for id in P}\n",
    "    dict_b = {id: dict_b[id] for id in P}\n",
    "\n",
    "    mean_a = np.mean(list(dict_a.values()))\n",
    "    mean_b = np.mean(list(dict_b.values()))\n",
    "    n = 0\n",
    "    d1 = 0\n",
    "    d2 = 0\n",
    "    \n",
    "    # calculate sums\n",
    "    for item in P:\n",
    "        n += ((dict_a[item] - mean_a) * (dict_b[item] - mean_b))\n",
    "        d1 += ((dict_a[item] - mean_a) ** 2)\n",
    "        d2 += ((dict_b[item] - mean_b) ** 2)\n",
    "    \n",
    "    # handle cases where n == 0 and d might be zero as well\n",
    "    if n == 0:\n",
    "        return 0\n",
    "\n",
    "    sim = n / (np.sqrt(d1) * np.sqrt(d2))\n",
    "    \n",
    "    # compare to scipys result, with some values the 16th decimal can be different -> round to 10 decimal places\n",
    "    #scipy_sim, p = stats.pearsonr(list(dict_a.values()), list(dict_b.values()))\n",
    "    #if np.round(sim, 10) == np.round(scipy_sim, 10):\n",
    "    #    print(sim, scipy_sim)\n",
    "    #    print('all ok')\n",
    "    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction function for predicting movie scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = userid, p = itemid, data = whole data set, nh = userids and similarities of users in the neighbourhood\n",
    "# if nh = None, neighbourhood is no limited\n",
    "def pearson_predict(a, p, data, nh=None):\n",
    "    # mean of ratings given by user a\n",
    "    mean_a = np.mean(list(data.loc[data['userid'] == a].rating))\n",
    "    \n",
    "\n",
    "    # dict containing all userids and ratings for itemid p\n",
    "    N = dict(zip(data.loc[data['itemid'] == p].userid, data.loc[data['itemid'] == p].rating))\n",
    "    n = 0\n",
    "    d = 0\n",
    "\n",
    "    if nh != None:\n",
    "        new_N = {}\n",
    "        # Neighbour hood given, limit userids and ratings to that\n",
    "        for id in nh:\n",
    "            if id in N:\n",
    "                new_N[id] = nh[id]\n",
    "        \n",
    "        # check if there are enough ratings in the neighbourhood\n",
    "        if len(new_N) > 0:\n",
    "            N = new_N\n",
    "\n",
    "            for b in N:\n",
    "                mean_b = np.mean(list(data.loc[data['userid'] == b].rating))\n",
    "                n += nh[b] * (N[b] - mean_b)\n",
    "                d +=  nh[b]\n",
    "\n",
    "            if n == 0:\n",
    "                return mean_a\n",
    "\n",
    "            return mean_a + n/d\n",
    "            \n",
    "    for b in N:\n",
    "        mean_b = np.mean(list(data.loc[data['userid'] == b].rating))\n",
    "        n += (pearson_correlation(a, b, data) * (N[b] - mean_b))\n",
    "        d += pearson_correlation(a, b, data)\n",
    "    \n",
    "    if n == 0:\n",
    "        return mean_a\n",
    "\n",
    "    return mean_a + n/d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show n most similar users for any given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_most_similar_users(a, n, data):\n",
    "    # all unique user ids\n",
    "    users = list(data['userid'].unique())\n",
    "\n",
    "    similarities = {}\n",
    "    for u in users:\n",
    "        if a != u:\n",
    "            sim = pearson_correlation(a, u, data)\n",
    "            similarities[u] = sim\n",
    "\n",
    "    # sort similarities based on dict values and return n highest values\n",
    "    similarities = dict(sorted(similarities.items(), key=lambda x: x[1], reverse=True))\n",
    "    return dict(list(similarities.items())[:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten most similar users to user 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid  similarity\n",
      "0      61    1.000000\n",
      "1     400    1.000000\n",
      "2     772    1.000000\n",
      "3     101    1.000000\n",
      "4     477    1.000000\n",
      "5     636    1.000000\n",
      "6     238    1.000000\n",
      "7     502    1.000000\n",
      "8     729    1.000000\n",
      "9     260    0.944911\n"
     ]
    }
   ],
   "source": [
    "USER = 10\n",
    "sim = n_most_similar_users(USER, 10, data)\n",
    "df = pd.DataFrame(list(zip(list(sim.keys()), list(sim.values()))), columns=['userid', 'similarity'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended 20 movies for the same user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    itemid  rating pred\n",
      "0     1360    14.129367\n",
      "1      247    12.233215\n",
      "2      138    12.170861\n",
      "3     1480     9.675820\n",
      "4     1628     9.357563\n",
      "5      360     6.513314\n",
      "6     1672     4.893793\n",
      "7     1671     4.206522\n",
      "8     1539     4.155533\n",
      "9     1432     4.034306\n",
      "10    1227     4.028426\n",
      "11    1332     3.808683\n",
      "12    1519     3.732777\n",
      "13     920     3.361101\n",
      "14    1066     3.312249\n",
      "15    1430     3.193389\n",
      "16     893     3.179575\n",
      "17    1146     3.162948\n",
      "18    1327     3.107773\n",
      "19    1250     3.004603\n"
     ]
    }
   ],
   "source": [
    "# all itemids\n",
    "movies = list(data['itemid'].unique())\n",
    "\n",
    "# movies the user has seen\n",
    "movies_user = list(data.loc[data['userid'] == USER].itemid)\n",
    "\n",
    "predictions = {}\n",
    "sim = n_most_similar_users(USER, 942, data)\n",
    "for movie in movies:\n",
    "    if movie not in movies_user:\n",
    "        pred = pearson_predict(USER, movie, data, sim)\n",
    "        predictions[movie] = pred\n",
    "\n",
    "most_relevant = dict(sorted(predictions.items(), key=lambda x: x[1], reverse=True))\n",
    "df = pd.DataFrame(list(zip(list(most_relevant.keys()), list(most_relevant.values()))), columns=['itemid', 'rating pred'])[:20]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f003dec6ba308691a84b457b1e8a70b369dfcd15d207cf34485669f808cefed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('recommender': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
