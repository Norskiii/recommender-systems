{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "names = ['userid', 'itemid', 'rating', 'timestamp']\n",
    "raw_data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "\n",
    "# save data in a numpy array where each user ratings have their own rows\n",
    "userids = sorted(list(raw_data['userid'].unique()))\n",
    "itemids = sorted(list(raw_data['itemid'].unique()))\n",
    "\n",
    "# first save in list of lists, use None values if user has not rated item\n",
    "data = [[None] * len(itemids) for x in range(len(userids))]\n",
    "\n",
    "# find ratings made by each user\n",
    "for i in range(len(userids)):\n",
    "    # dict of ratings for user i+1 (key = itemid, value = rating)\n",
    "    user_ratings = dict(zip(raw_data.loc[raw_data['userid'] == (i+1)].itemid, raw_data.loc[raw_data['userid'] == (i+1)].rating))\n",
    "    for j in range(len(itemids)):\n",
    "        # check if user has rated item with id j+1\n",
    "        if j+1 in user_ratings:\n",
    "            data[i][j] = user_ratings[j+1]\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based collaborative filtering approach from Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = userids, data = whole data set\n",
    "def similarity(a,b, data):\n",
    "    data_a = data[a-1] # remember that indexing starts from 0, but userids from 1\n",
    "    data_b = data[b-1]\n",
    "\n",
    "    # dicts with itemids and ratings\n",
    "    dict_a = {i: r for i, r in enumerate(data_a, start=1) if r is not None}\n",
    "    dict_b = {i: r for i, r in enumerate(data_b, start=1) if r is not None}\n",
    "\n",
    "    # intersections of common itemids\n",
    "    P = list(set(dict_a).intersection(set(dict_b)))\n",
    "\n",
    "    if len(P) < 2:\n",
    "        return 0\n",
    "\n",
    "    # keep only common itemids\n",
    "    dict_a = {id: dict_a[id] for id in P}\n",
    "    dict_b = {id: dict_b[id] for id in P}\n",
    "\n",
    "    # Create constants\n",
    "    const_a = list(dict_a.values())\n",
    "    const_b = list(dict_b.values())\n",
    "\n",
    "    sim, p = stats.pearsonr(const_a, const_b)\n",
    "\n",
    "    # Check for NaN\n",
    "    if sim != sim:\n",
    "        return 0\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Anaconda\\envs\\recommender\\lib\\site-packages\\scipy\\stats\\stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "# Similarity matrix\n",
    "N = 0\n",
    "sim_matrix = [[1] * len(userids) for x in range(len(userids))]\n",
    "for i in range(len(userids)):\n",
    "    for j in range(i+1, len(userids)):\n",
    "        sim_matrix[i][j] = sim_matrix[j][i] = similarity(i+1, j+1, data)\n",
    "\n",
    "sim_matrix = np.array(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = userid, p = itemid, data = whole data set, \n",
    "# sim = similarity matrix t = similarity threshold\n",
    "def predict(a, p, data, sim_matrix, t):\n",
    "    sim = sim_matrix[a-1]\n",
    "    # mean of ratings given by user a\n",
    "    mean_a = np.mean([r for r in data[a-1] if r is not None])\n",
    "\n",
    "    # transform similarities to dict (key = userid, value = similarity) and filter out unvanted similarities\n",
    "    sim = {i: s for i, s in enumerate(sim, start=1) if s >= t}\n",
    "\n",
    "    n = 0\n",
    "    d = 0\n",
    "\n",
    "    for b in sim:\n",
    "        # chekc if user b has not rated the item\n",
    "        if data[b-1][p-1] == None:\n",
    "            continue\n",
    "\n",
    "        mean_b = np.mean([r for r in data[b-1] if r is not None])\n",
    "        n += sim[b] * (data[b-1][p-1] - mean_b)\n",
    "        d += sim[b]\n",
    "\n",
    "    if n == 0:\n",
    "        return mean_a\n",
    "\n",
    "    return mean_a + n/d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average aggregation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = groud of users (list of usedids), i = itemid, data = whole dataset\n",
    "def average_aggregation(g, i, data):\n",
    "    # ratings for item i, given by users in the group\n",
    "    ratings = []\n",
    "\n",
    "    # obtaing ratings, either from data or predict it\n",
    "    for user in g:\n",
    "        rating = data[user-1][i-1]\n",
    "        if rating == None:\n",
    "            rating = predict(user, i, data, sim_matrix, 10)\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    return np.average(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least misery aggregation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_misery_aggregation(g, i, data):\n",
    "    # ratings for item i, given by users in the group\n",
    "    ratings = []\n",
    "\n",
    "    # obtaing ratings, either from data or predict it\n",
    "    for user in g:\n",
    "        rating = data[user-1][i-1]\n",
    "        if rating == None:\n",
    "            rating = predict(user, i, data, sim_matrix, 10)\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    return np.min(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 recommendations for a group of 3 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = [1, 11, 111]\n",
    "\n",
    "# dicts for both aggregation ratings (key=itemid, value=group rating)\n",
    "avg_ratings = {}\n",
    "lm_ratings = {}\n",
    "\n",
    "for i in itemids:\n",
    "    avg_ratings[i] = average_aggregation(g, i, data)\n",
    "    lm_ratings[i] = least_misery_aggregation(g, i, data)\n",
    "\n",
    "# sort both dicts so that highly rated items for the group are first\n",
    "avg_ratings = dict(sorted(avg_ratings.items(), key=lambda x: x[1], reverse=True))\n",
    "lm_ratings = dict(sorted(lm_ratings.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations with average method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    itemid    rating\n",
      "0      258  4.666667\n",
      "1        9  4.513889\n",
      "2       15  4.513889\n",
      "3      173  4.513889\n",
      "4      196  4.513889\n",
      "5      268  4.513889\n",
      "6      269  4.488029\n",
      "7      286  4.203431\n",
      "8       28  4.180556\n",
      "9       86  4.180556\n",
      "10     100  4.180556\n",
      "11     111  4.180556\n",
      "12     191  4.180556\n",
      "13     208  4.180556\n",
      "14     242  4.154696\n",
      "15     277  4.050654\n",
      "16     318  4.050654\n",
      "17     332  4.050654\n",
      "18     357  4.050654\n",
      "19     423  4.050654\n"
     ]
    }
   ],
   "source": [
    "recommendations = dict(list(avg_ratings.items())[:20])\n",
    "df = pd.DataFrame(list(zip(list(recommendations.keys()), list(recommendations.values()))), columns=['itemid', 'rating'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations with least misery method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    itemid    rating\n",
      "0      258  4.000000\n",
      "1      286  3.610294\n",
      "2      301  3.610294\n",
      "3        9  3.541667\n",
      "4       15  3.541667\n",
      "5       22  3.541667\n",
      "6       28  3.541667\n",
      "7       47  3.541667\n",
      "8       51  3.541667\n",
      "9       56  3.541667\n",
      "10      79  3.541667\n",
      "11      86  3.541667\n",
      "12     100  3.541667\n",
      "13     107  3.541667\n",
      "14     111  3.541667\n",
      "15     135  3.541667\n",
      "16     173  3.541667\n",
      "17     185  3.541667\n",
      "18     191  3.541667\n",
      "19     194  3.541667\n"
     ]
    }
   ],
   "source": [
    "recommendations = dict(list(lm_ratings.items())[:20])\n",
    "df = pd.DataFrame(list(zip(list(recommendations.keys()), list(recommendations.values()))), columns=['itemid', 'rating'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose that the disagreements between users are taken into account with disagreement variance (Sihem Amer-Yahia, Senjuti Basu Roy, Ashish Chawlat, Gautam Das, and Cong Yu. 2009. Group recommendation: semantics and efficiency. Proc. VLDB Endow. 2, 1 (August 2009), 754â€“765. DOI:https://doi-org.libproxy.tuni.fi/10.14778/1687627.1687713).\n",
    "\n",
    "Disagreement variance is defined as \n",
    "$dis(g,i) = \\frac{1}{|g|}\\sum \\limits _{u\\in g} (r^{*}(u, i) - mean)^2 $, where $mean$ is the mean of ratings the users in group $g$ have given to item $i$.\n",
    "\n",
    "Using the calculated variance, group recommendations are computed with consensus function defined as\n",
    "$con(g,i) = w_1 \\times r^{*}(g,i) + w_2 \\times (1-dis(g,i))$, where $w_1 + w_2 = 1$.\n",
    "These weights define how important we want the group disagreement to be in the recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreement_variance(g, i, data):\n",
    "    # ratings for item i, given by users in the group\n",
    "    ratings = []\n",
    "\n",
    "    # obtaing ratings, either from data or predict it\n",
    "    for user in g:\n",
    "        rating = data[user-1][i-1]\n",
    "        if rating == None:\n",
    "            rating = predict(user, i, data, sim_matrix, 10)\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    ratings_mean = np.mean(ratings)\n",
    "\n",
    "    # calculate and return the disagreement variance acording to the formula presented above\n",
    "    dis = (1/len(ratings) * np.sum([(r - ratings_mean) ** 2 for r  in ratings]))\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consensus(g, i, data):\n",
    "    w1 = 0.9\n",
    "    w2 = 1-w1\n",
    "    return w1 * average_aggregation(g, i, data) + w2 * (1-disagreement_variance(g, i, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show top 20 recommendations, where disagreements have been taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    itemid    rating\n",
      "0      258  4.277778\n",
      "1        9  4.115239\n",
      "2       15  4.115239\n",
      "3      173  4.115239\n",
      "4      196  4.115239\n",
      "5      268  4.115239\n",
      "6      269  4.086804\n",
      "7      286  3.848831\n",
      "8       28  3.825424\n",
      "9       86  3.825424\n",
      "10     100  3.825424\n",
      "11     111  3.825424\n",
      "12     191  3.825424\n",
      "13     208  3.825424\n",
      "14     242  3.798713\n",
      "15     277  3.700447\n",
      "16     318  3.700447\n",
      "17     332  3.700447\n",
      "18     357  3.700447\n",
      "19     423  3.700447\n"
     ]
    }
   ],
   "source": [
    "g = [1, 11, 111]\n",
    "# dict for group ratings for all items (key=itemid, value=group rating for item)\n",
    "ratings = {}\n",
    "\n",
    "for i in itemids:\n",
    "    ratings[i] = consensus(g, i, data)\n",
    "\n",
    "# sort dict so that highly rated items for the group are first\n",
    "ratings = dict(sorted(ratings.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "recommendations = dict(list(ratings.items())[:20])\n",
    "df = pd.DataFrame(list(zip(list(recommendations.keys()), list(recommendations.values()))), columns=['itemid', 'rating'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f003dec6ba308691a84b457b1e8a70b369dfcd15d207cf34485669f808cefed"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
